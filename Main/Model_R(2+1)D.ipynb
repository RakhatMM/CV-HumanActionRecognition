{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839fb5b4-ea79-4c59-9342-10797acd2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision.models.video import r2plus1d_18\n",
    "from torchvision.io import read_video\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd432f1-f727-4596-86d1-f9b3b017ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, frame_count, resize, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.classes = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        self.classes.sort()\n",
    "        self.class_to_idx = {self.classes[i]: i for i in range(len(self.classes))}\n",
    "        self.frame_count = frame_count\n",
    "        self.resize = resize\n",
    "\n",
    "        for idx, action_class in enumerate(self.classes):\n",
    "            class_path = os.path.join(root_dir, action_class)\n",
    "            for video_file in os.listdir(class_path):\n",
    "                if video_file.endswith(('.mp4', '.avi')) and not video_file.startswith('.'):\n",
    "                    self.data.append(os.path.join(class_path, video_file))\n",
    "                    self.labels.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        video, _, _ = read_video(video_path)\n",
    "    \n",
    "        # Process video\n",
    "        video = self.process_video(video)\n",
    "    \n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "    \n",
    "        return video, label\n",
    "\n",
    "    import torch\n",
    "\n",
    "    def process_video(self, video):\n",
    "        # video is a tensor of shape [frames, height, width, channels]\n",
    "        video = video.float()\n",
    "    \n",
    "        resized_frames = []\n",
    "        for i in range(min(self.frame_count, video.shape[0])):\n",
    "            frame = video[i]\n",
    "    \n",
    "            # Convert to RGB if grayscale\n",
    "            if frame.size(2) == 1:\n",
    "                frame = frame.repeat(1, 1, 3)\n",
    "    \n",
    "            # Permute to [channels, height, width]\n",
    "            frame = frame.permute(2, 0, 1)\n",
    "    \n",
    "            # Resize frame\n",
    "            frame = F.interpolate(frame.unsqueeze(0), size=self.resize, mode='bilinear', align_corners=False).squeeze(0)\n",
    "    \n",
    "            resized_frames.append(frame)\n",
    "    \n",
    "        # Pad if necessary\n",
    "        while len(resized_frames) < self.frame_count:\n",
    "            resized_frames.append(resized_frames[-1])\n",
    "    \n",
    "        # Stack and permute to [channels, frames, height, width]\n",
    "        video_tensor = torch.stack(resized_frames, dim=0).permute(1, 0, 2, 3)\n",
    "    \n",
    "        return video_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a501a-0b5e-4f5d-975b-df550616cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "root_dir = 'merged'  \n",
    "frame_count = 16\n",
    "resize = (224, 224)\n",
    "dataset = VideoDataset(root_dir, frame_count, resize)\n",
    "\n",
    "train_ratio = 0.8\n",
    "labels = dataset.labels\n",
    "\n",
    "# Perform a stratified split\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(labels)), \n",
    "    test_size=1 - train_ratio, \n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "# Create Subset objects for train and test datasets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create data loaders for train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98665a12-043c-4627-80c9-b5fae72dbecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'r2plus1d_model_b2.pth'\n",
    "# PATH = 'r2plus1d_model_b16.pth'\n",
    "model = r2plus1d_18()\n",
    "num_classes = len(dataset.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a77fec-9399-459b-b314-682398f78cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "    train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "    for videos, labels in train_bar:\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(videos)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * videos.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "        train_bar.set_postfix(loss=train_loss/total_train, accuracy=100.0*train_correct/total_train)\n",
    "\n",
    "torch.save(model.state_dict(), 'r2plus1d_model_b2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880553f-2ad5-4057-851a-272480c0cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Initialize the counters for top-1, top-3, and top-5 accuracy\n",
    "top1_correct = 0\n",
    "top3_correct = 0\n",
    "top5_correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for videos, labels in test_loader:\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(videos)\n",
    "        \n",
    "        # Get the top 5 predictions from the outputs\n",
    "        _, top5 = outputs.topk(5, 1, True, True)\n",
    "        top5 = top5.t()\n",
    "        \n",
    "        # Increment the total counter\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Check if the true label is within the top 5 predictions\n",
    "        correct = top5.eq(labels.view(1, -1).expand_as(top5))\n",
    "        \n",
    "        # top-1 accuracy is the sum of the first row of correct\n",
    "        top1_correct += correct[0].float().sum(0, keepdim=True).item()\n",
    "        # top-3 accuracy is the sum of the first 3 rows of correct\n",
    "        top3_correct += correct[:3].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "        # top-5 accuracy is the sum of all 5 rows of correct\n",
    "        top5_correct += correct.reshape(-1).float().sum(0, keepdim=True).item()\n",
    "\n",
    "# Calculate the top-1, top-3, and top-5 accuracies\n",
    "acc1 = top1_correct / total\n",
    "acc3 = top3_correct / total\n",
    "acc5 = top5_correct / total\n",
    "print(f\"Top-1 Accuracy: {acc1 * 100:.2f}%\")\n",
    "print(f\"Top-3 Accuracy: {acc3 * 100:.2f}%\")\n",
    "print(f\"Top-5 Accuracy: {acc5 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345c179-ad59-4db0-97ae-be7448c1516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Initialize top-k correct prediction counters\n",
    "topk_correct = {k: np.zeros(len(dataset.classes)) for k in [1, 3, 5]}\n",
    "topk_total = np.zeros(len(dataset.classes))\n",
    "\n",
    "# Initialize confusion matrix\n",
    "conf_matrix = np.zeros((len(dataset.classes), len(dataset.classes)), dtype=int)\n",
    "\n",
    "# Process each batch in test_loader\n",
    "with torch.no_grad():\n",
    "    for videos, labels in test_loader:\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(videos)\n",
    "        \n",
    "        # Get top-5 predictions\n",
    "        _, top5 = outputs.topk(5, 1, True, True)\n",
    "        \n",
    "        for i, label in enumerate(labels):\n",
    "            y_true.append(label.item())\n",
    "            y_pred.append(top5[i, 0].item())  # Add top-1 prediction for the confusion matrix\n",
    "            topk_total[label.item()] += 1\n",
    "            \n",
    "            # Check if the true label is in the top k predictions\n",
    "            true_label = label.item()\n",
    "            pred_labels = top5[i].tolist()\n",
    "            for k in [1, 3, 5]:\n",
    "                if true_label in pred_labels[:k]:\n",
    "                    topk_correct[k][true_label] += 1\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred, labels=list(range(len(dataset.classes))))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(10, 8)) \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(conf_matrix, dataset.classes)\n",
    "\n",
    "# Calculate and print Top-1, Top-3, and Top-5 accuracies for each class\n",
    "for i, class_name in enumerate(dataset.classes):\n",
    "    print(f\"\\nAccuracy for class {class_name}:\")\n",
    "    for k in [1, 3, 5]:\n",
    "        if topk_total[i] > 0:\n",
    "            accuracy = (topk_correct[k][i] / topk_total[i]) * 100\n",
    "            print(f\"  Top-{k}: {accuracy:.2f}%\")\n",
    "        else:\n",
    "            print(f\"  Top-{k}: No samples available for this class.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba67e21-0ead-4484-8844-a06415bf6f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
